#!/bin/env python3

import multiprocessing
import threading
import requests
import platform
import pathlib
import tomllib
import fnmatch
import lzma
import time
import zlib
import sys

import urllib.parse

from pydantic.dataclasses import dataclass
from pydantic.tools import parse_obj_as

from datetime import datetime
from typing import Optional


@dataclass
match machine:
    case "i686": machine = "i386"
    case "x86_64": machine = "amd64"
    case "armv7l": machine = "armhf"
    case "aarch64": machine = "arm64"
    case _: raise ValueError(machine)

DEBIAN_BINARY = f"binary-{machine}"

# @todo: Don't output in critical section. Use queue.
output_lock = threading.Lock()


class PackageSpec():
    url: Optional[str] = None
    name: Optional[str] = None
    not_deps: Optional[list[str]] = None
    version: Optional[str] = None
    last_modified: Optional[str | datetime] = None
    deps: Optional[list[str]] = None


@dataclass
class GithubSource():
    repository: str
    packages: Optional[dict[str, PackageSpec]] = None


@dataclass
class GithubAsset():
    name: str
    updated_at: str
    browser_download_url: str


@dataclass
class DebianSource():
    base_url: str
    distribution: str
    components: list[str]
    packages: Optional[dict[str, PackageSpec]] = None
    whitelist: Optional[list[str]] = None
    blacklist: Optional[list[str]] = None
    whitelist_autoappend: bool = False


@dataclass
class GithubRelease():
    assets: list[GithubAsset]


@dataclass
class Config():
    github_token: Optional[str] = None
    sources: Optional[dict[str, DebianSource | GithubSource | PackageSpec]] = None


@dataclass
class DebianPackage():
    package: str
    version: str
    depends: list[str]
    filename: str


def parse_debian_package(string: bytes | str) -> dict[str, DebianPackage]:
    if isinstance(string, bytes):
        string = string.decode()

    assert isinstance(string, str)

    packages = dict()
    for package_string in string.split("\n\n"):
        if len(package_string) == 0:
            continue

        package = dict()
        for entry_string in package_string.split("\n"):
            # skip continutations
            if entry_string[0].isspace():
                continue

            key, value = entry_string.split(": ", 1)
            package[key.lower()] = value

        if "depends" in package:
            package["depends"] = [re.sub(" .*", "", p) for p in re.split(", | \\| ", package["depends"])]
        else:
            package["depends"] = []

        package = parse_obj_as(DebianPackage, package)

        packages[package.package] = package

    return packages


def print_package(p: PackageSpec):
    global output_lock

    with output_lock:
        print(f"[{p.name}]")

        if p.url is not None:
            print(f"url = {p.url}")

        if p.deps is not None:
            print(f"deps = {' '.join(p.deps)}")

        if p.not_deps is not None:
            print(f"not_deps = {' '.join(p.not_deps)}")

        if p.version is not None:
            print(f"version = {p.version}")

        if p.last_modified is not None:
            assert isinstance(p.last_modified, datetime)

            last_modified_unix = int(time.mktime(p.last_modified.timetuple()))
            print(f"last_modified = {last_modified_unix}")

        print()


def process_single_source(name, source):
    global machine
    print(f"Syncing {name}", file=sys.stderr)

    if isinstance(source, DebianSource):
        parts = urllib.parse.urlparse(source.base_url)
        base_path = pathlib.Path(parts.path if parts.path else "/")
        distribution_path = base_path/source.distribution
        dists_path = distribution_path/"dists"
        binary_path = dists_path/'/'.join(source.components)/DEBIAN_BINARY

        try_fetch = [(binary_path/"Packages.xz", lambda d:
                      lzma.decompress(d)),
                     (binary_path/"Packages.gz", lambda d:
                      zlib.decompress(d, 16+zlib.MAX_WBITS)),
                     (binary_path/"Packages",
                      lambda d: d)]
        for path, function in try_fetch:
            package_url = urllib.parse.urlunparse((parts.scheme,
                                                   parts.netloc,
                                                   path.as_posix(),
                                                   "",
                                                   "",
                                                   ""))
            response = requests.get(package_url)

            if response.status_code == 200:
                content = function(response.content)
                break
        else:
            print(f"{name}: request failed", file=sys.stderr)
            return

        packages = parse_debian_package(content)

        for k in packages.keys():
            if source.whitelist is not None and k not in source.whitelist:
                continue

            if source.blacklist is not None and k in source.blacklist:
                continue

            v = packages[k]

            manual_packages = source.packages if source.packages is not None else {}

            deb_path = distribution_path/v.filename
            deb_url = urllib.parse.urlunparse((parts.scheme,
                                               parts.netloc,
                                               deb_path.as_posix(),
                                               "",
                                               "",
                                               ""))

            p = manual_packages.setdefault(k, PackageSpec(name=None,
                                                          not_deps=None,
                                                          deps=None,
                                                          url=None,
                                                          last_modified=None,
                                                          version=None))
            p.name = p.name if p.name is not None else k
            p.url = p.url if p.url is not None else deb_url
            p.version = p.version if p.version is not None else v.version
            # p.deps = p.deps if p.deps is not None else v.depends

            print_package(p)
    elif isinstance(source, GithubSource):
        if source.packages is None:
            return

        path = pathlib.Path("/")/"repos"/source.repository/"releases"/"latest"
        url = urllib.parse.urlunparse(("https",
                                       "api.github.com",
                                       path.as_posix(),
                                       "",
                                       "",
                                       ""))

        response = requests.get(url)
        release = parse_obj_as(GithubRelease, response.json())

        for k in source.packages.keys():
            for asset in release.assets:
                if fnmatch.fnmatch(asset.name, k):
                    break
            else:
                continue

            p = source.packages[k]

            t = datetime.strptime(asset.updated_at, '%Y-%m-%dT%H:%M:%SZ')
            if p.name is None:
                p.name = name

            if p.url is None:
                p.url = asset.browser_download_url

            if p.last_modified is None:
                p.last_modified = t

            print_package(p)

    elif isinstance(source, PackageSpec):
        if source.url is None:
            print(f"{name}: No URL, skipping.", file=sys.stderr)
            return

        response = requests.head(source.url, allow_redirects=True)
        t = datetime.strptime(response.headers["last-modified"],
                              "%a, %d %b %Y %H:%M:%S %Z")

        if source.name is None:
            source.name = name

        if source.last_modified is None:
            source.last_modified = t

        print_package(source)


def thread_fn(begin, length):
    assert config.sources is not None

    for name, source in list(config.sources.items())[begin:begin+length]:
        process_single_source(name, source)


if __name__ == '__main__':
    with open("vpkg-sync.toml", "rb") as config_file:
        p = tomllib.load(config_file)

    config = parse_obj_as(Config, p)

    if config.sources is None:
        exit(0)

    try:
        numthreads = multiprocessing.cpu_count()
    except NotImplementedError:
        numthreads = 1

    numitems = len(config.sources)
    if numthreads > numitems:
        numthreads = numitems

    if numthreads == 1:
        for name, source in config.sources.items():
            process_single_source(name, source)
    else:
        for i in range(0, numthreads):
            size = (numitems + (numthreads - 1)) // numthreads
            t = threading.Thread(target=thread_fn, args=(i*size, size))
            t.start()
